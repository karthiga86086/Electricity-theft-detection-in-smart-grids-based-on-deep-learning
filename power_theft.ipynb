{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7TrLazaR8pZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho5MpJa9SK5V"
      },
      "outputs": [],
      "source": [
        "rawData = pd.read_excel('/content/drive/MyDrive/data/df.csv.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDb8ACiffe2d",
        "outputId": "f7201fcd-3b80-4131-e9d9-06a1bc140e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "zP7Igxy7St8o",
        "outputId": "9d6fca43-7be7-4035-e6e9-8be68bbb3e4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            CONS_NO  FLAG  2014-01-01 00:00:00  \\\n",
              "0  0387DD8A07E07FDA6271170F86AD9151     1                  NaN   \n",
              "1  01D6177B5D4FFE0CABA9EF17DAFC2B84     1                  NaN   \n",
              "2  4B75AC4F2D8434CFF62DB64D0BB43103     1                  NaN   \n",
              "3  B32AC8CC6D5D805AC053557AB05F5343     1                  NaN   \n",
              "4  EDFC78B07BA2908B3395C4EB2304665E     1                  2.9   \n",
              "\n",
              "   2014-01-10 00:00:00  2014-01-11 00:00:00  2014-01-12 00:00:00  \\\n",
              "0                  NaN                  NaN                  NaN   \n",
              "1                  NaN                  NaN                  NaN   \n",
              "2                  NaN                  NaN                  NaN   \n",
              "3                  NaN                  NaN                  NaN   \n",
              "4                 3.42                 3.81                 4.58   \n",
              "\n",
              "   2014-01-13 00:00:00  2014-01-14 00:00:00  2014-01-15 00:00:00  \\\n",
              "0                  NaN                  NaN                  NaN   \n",
              "1                  NaN                  NaN                  NaN   \n",
              "2                  NaN                  NaN                  NaN   \n",
              "3                  NaN                  NaN                  NaN   \n",
              "4                 3.56                 4.25                 3.86   \n",
              "\n",
              "   2014-01-16 00:00:00  ...  2016-09-28 00:00:00  2016-09-29 00:00:00  \\\n",
              "0                  NaN  ...                10.12                 9.96   \n",
              "1                  NaN  ...                 0.00                 0.00   \n",
              "2                  NaN  ...                  NaN                  NaN   \n",
              "3                  NaN  ...                 6.50                 9.99   \n",
              "4                 3.53  ...                17.77                10.37   \n",
              "\n",
              "   2016-09-03 00:00:00  2016-09-30 00:00:00  2016-09-04 00:00:00  \\\n",
              "0                16.92                 7.60                27.22   \n",
              "1                 0.00                 0.00                 0.00   \n",
              "2                  NaN                  NaN                  NaN   \n",
              "3                11.78                18.59                26.80   \n",
              "4                15.32                13.51                12.23   \n",
              "\n",
              "   2016-09-05 00:00:00  2016-09-06 00:00:00  2016-09-07 00:00:00  \\\n",
              "0                18.05                26.47                18.75   \n",
              "1                 0.00                 0.00                 0.00   \n",
              "2                  NaN                  NaN                  NaN   \n",
              "3                18.57                14.59                12.82   \n",
              "4                14.68                16.35                18.14   \n",
              "\n",
              "   2016-09-08 00:00:00  2016-09-09 00:00:00  \n",
              "0                17.84                14.92  \n",
              "1                 0.00                 0.00  \n",
              "2                  NaN                  NaN  \n",
              "3                19.37                15.92  \n",
              "4                18.41                17.31  \n",
              "\n",
              "[5 rows x 1036 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-667953b0-4c11-408d-a7ca-76e06e3f6585\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CONS_NO</th>\n",
              "      <th>FLAG</th>\n",
              "      <th>2014-01-01 00:00:00</th>\n",
              "      <th>2014-01-10 00:00:00</th>\n",
              "      <th>2014-01-11 00:00:00</th>\n",
              "      <th>2014-01-12 00:00:00</th>\n",
              "      <th>2014-01-13 00:00:00</th>\n",
              "      <th>2014-01-14 00:00:00</th>\n",
              "      <th>2014-01-15 00:00:00</th>\n",
              "      <th>2014-01-16 00:00:00</th>\n",
              "      <th>...</th>\n",
              "      <th>2016-09-28 00:00:00</th>\n",
              "      <th>2016-09-29 00:00:00</th>\n",
              "      <th>2016-09-03 00:00:00</th>\n",
              "      <th>2016-09-30 00:00:00</th>\n",
              "      <th>2016-09-04 00:00:00</th>\n",
              "      <th>2016-09-05 00:00:00</th>\n",
              "      <th>2016-09-06 00:00:00</th>\n",
              "      <th>2016-09-07 00:00:00</th>\n",
              "      <th>2016-09-08 00:00:00</th>\n",
              "      <th>2016-09-09 00:00:00</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0387DD8A07E07FDA6271170F86AD9151</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>10.12</td>\n",
              "      <td>9.96</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.60</td>\n",
              "      <td>27.22</td>\n",
              "      <td>18.05</td>\n",
              "      <td>26.47</td>\n",
              "      <td>18.75</td>\n",
              "      <td>17.84</td>\n",
              "      <td>14.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01D6177B5D4FFE0CABA9EF17DAFC2B84</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4B75AC4F2D8434CFF62DB64D0BB43103</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B32AC8CC6D5D805AC053557AB05F5343</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>6.50</td>\n",
              "      <td>9.99</td>\n",
              "      <td>11.78</td>\n",
              "      <td>18.59</td>\n",
              "      <td>26.80</td>\n",
              "      <td>18.57</td>\n",
              "      <td>14.59</td>\n",
              "      <td>12.82</td>\n",
              "      <td>19.37</td>\n",
              "      <td>15.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EDFC78B07BA2908B3395C4EB2304665E</td>\n",
              "      <td>1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.42</td>\n",
              "      <td>3.81</td>\n",
              "      <td>4.58</td>\n",
              "      <td>3.56</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.86</td>\n",
              "      <td>3.53</td>\n",
              "      <td>...</td>\n",
              "      <td>17.77</td>\n",
              "      <td>10.37</td>\n",
              "      <td>15.32</td>\n",
              "      <td>13.51</td>\n",
              "      <td>12.23</td>\n",
              "      <td>14.68</td>\n",
              "      <td>16.35</td>\n",
              "      <td>18.14</td>\n",
              "      <td>18.41</td>\n",
              "      <td>17.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1036 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-667953b0-4c11-408d-a7ca-76e06e3f6585')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-667953b0-4c11-408d-a7ca-76e06e3f6585 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-667953b0-4c11-408d-a7ca-76e06e3f6585');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "rawData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP-XW_iYSw7a"
      },
      "outputs": [],
      "source": [
        "#removing column 1 and 2(making InfoData)\n",
        "infoData = pd.DataFrame()\n",
        "infoData['FLAG'] = rawData['FLAG']\n",
        "infoData['CONS_NO'] = rawData['CONS_NO']\n",
        "data = rawData.drop(['FLAG', 'CONS_NO'], axis=1)   #axis 1 column ,axis 0 row\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OCID-C_WBel",
        "outputId": "58998800-7485-4bdc-a2f1-e04add5a07c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33841, 1034)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V469dTMIUDlh"
      },
      "outputs": [],
      "source": [
        "#droping duplicate row\n",
        "dropIndex = data[data.duplicated()].index  # duplicates drop\n",
        "data = data.drop(dropIndex, axis=0)   #droping duplicate value present wen two row are same\n",
        "infoData = infoData.drop(dropIndex, axis=0) #droping duplicate index infodata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uoH3stLV6en"
      },
      "outputs": [],
      "source": [
        "#removing row with all zero(Nan) value\n",
        "zeroIndex = data[(data.sum(axis=1) == 0)].index  # zero rows drop\n",
        "data = data.drop(zeroIndex, axis=0) \n",
        "infoData = infoData.drop(zeroIndex, axis=0)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "382hYwaWV9LW"
      },
      "outputs": [],
      "source": [
        "#change column name to dates(2014/1/1 to 2014-01-01)\n",
        "data.columns = pd.to_datetime(data.columns)  #columns reindexing according to dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swYVlwwbWM3V"
      },
      "outputs": [],
      "source": [
        "# reindex row name (as some row has been remove till this step due to duplicate or all nan values)\n",
        "data.reset_index(inplace=True, drop=True)  # index sorting\n",
        "infoData.reset_index(inplace=True, drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "posl_FnKWSvf"
      },
      "outputs": [],
      "source": [
        "#filling nan value using neighbouring value (middle missing value replace by average \n",
        "#and other by maximum 2 distance element)\n",
        "data = data.interpolate(method='linear', limit=2, limit_direction='both', axis=0).fillna(0) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-OPcQD1WZ4H"
      },
      "outputs": [],
      "source": [
        "#removing erronoues value(fixing outliers)\n",
        "for i in range(data.shape[0]):  # outliers treatment\n",
        "    m = data.loc[i].mean()\n",
        "    st = data.loc[i].std()\n",
        "    data.loc[i] = data.loc[i].mask(data.loc[i] > (m + 3 * st), other=m + 3 * st)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYs7l8e_Whzt"
      },
      "outputs": [],
      "source": [
        "# save preprocessed data without scaling\n",
        "data.to_csv(r'visualization.csv', index=False, header=True)  # preprocessed data without scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_nvEiNNWxpH"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"visualization.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "mHADl7NIW52U",
        "outputId": "5a67eb53-c5bd-4a50-87d0-bca608476acf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       2014-01-01  2014-01-10  2014-01-11  2014-01-12  2014-01-13  2014-01-14  \\\n",
              "0           0.000       0.000        0.00       0.000        0.00        0.00   \n",
              "1           2.900       3.420        3.81       4.580        3.56        4.25   \n",
              "2           2.900       3.420        3.81       4.580        3.56        4.25   \n",
              "3           2.900       3.420        3.81       4.580        3.56        4.25   \n",
              "4           1.505       1.975        2.13       2.545        2.44        2.48   \n",
              "...           ...         ...         ...         ...         ...         ...   \n",
              "32183      18.900       0.000        0.00      24.080       17.99       18.70   \n",
              "32184       0.000       0.000        0.00       0.000        0.00        0.00   \n",
              "32185       1.840       1.820        2.26       1.800        1.24        1.69   \n",
              "32186       0.000       0.000        0.00       0.000        0.00        0.00   \n",
              "32187       0.080       0.250        0.08       0.100        0.00        0.00   \n",
              "\n",
              "       2014-01-15  2014-01-16  2014-01-17  2014-01-18  ...  2016-09-28  \\\n",
              "0            0.00       0.000        0.00       0.000  ...       10.12   \n",
              "1            3.86       3.530        3.41       0.850  ...        8.31   \n",
              "2            3.86       3.530        3.41       0.850  ...        6.50   \n",
              "3            3.86       3.530        3.41       0.850  ...       17.77   \n",
              "4            1.99       2.025        1.98       0.795  ...        2.82   \n",
              "...           ...         ...         ...         ...  ...         ...   \n",
              "32183       18.88      16.680       21.17      14.580  ...        7.13   \n",
              "32184        0.00       0.000        0.00       0.000  ...      223.88   \n",
              "32185        1.95       1.200        1.29       1.360  ...        0.83   \n",
              "32186        0.00       0.000        0.00       0.000  ...        5.97   \n",
              "32187        0.00       0.000        0.05       0.140  ...        0.24   \n",
              "\n",
              "       2016-09-29  2016-09-03  2016-09-30  2016-09-04  2016-09-05  2016-09-06  \\\n",
              "0           9.960       16.92    7.600000   27.220000       18.05       26.47   \n",
              "1           9.975       14.35   13.095000   26.793616       18.31       20.53   \n",
              "2           9.990       11.78   18.590000   26.800000       18.57       14.59   \n",
              "3          10.370       15.32   13.510000   12.230000       14.68       16.35   \n",
              "4           5.520        3.12    3.130000    4.200000        3.23        3.85   \n",
              "...           ...         ...         ...         ...         ...         ...   \n",
              "32183       8.740        6.26    7.940000    8.240000        9.36        9.00   \n",
              "32184     184.340      172.69  205.440000  207.640000      233.38      194.74   \n",
              "32185       4.830        6.50   37.437344    7.330000        5.83        7.00   \n",
              "32186       5.700        6.41    6.880000    9.700000        8.25        8.91   \n",
              "32187       0.450        0.16    0.160000    0.170000        0.19        0.29   \n",
              "\n",
              "       2016-09-07  2016-09-08  2016-09-09  \n",
              "0          18.750      17.840       14.92  \n",
              "1          15.785      18.605       15.42  \n",
              "2          12.820      19.370       15.92  \n",
              "3          18.140      18.410       17.31  \n",
              "4           2.780       3.550        2.54  \n",
              "...           ...         ...         ...  \n",
              "32183       8.000       7.530        6.71  \n",
              "32184     183.910     182.190      256.04  \n",
              "32185       5.480       5.160        8.16  \n",
              "32186       8.300       7.410        7.80  \n",
              "32187       0.230       0.200        0.26  \n",
              "\n",
              "[32188 rows x 1034 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7eba0f27-fca5-484a-83dc-b0185328fdb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2014-01-01</th>\n",
              "      <th>2014-01-10</th>\n",
              "      <th>2014-01-11</th>\n",
              "      <th>2014-01-12</th>\n",
              "      <th>2014-01-13</th>\n",
              "      <th>2014-01-14</th>\n",
              "      <th>2014-01-15</th>\n",
              "      <th>2014-01-16</th>\n",
              "      <th>2014-01-17</th>\n",
              "      <th>2014-01-18</th>\n",
              "      <th>...</th>\n",
              "      <th>2016-09-28</th>\n",
              "      <th>2016-09-29</th>\n",
              "      <th>2016-09-03</th>\n",
              "      <th>2016-09-30</th>\n",
              "      <th>2016-09-04</th>\n",
              "      <th>2016-09-05</th>\n",
              "      <th>2016-09-06</th>\n",
              "      <th>2016-09-07</th>\n",
              "      <th>2016-09-08</th>\n",
              "      <th>2016-09-09</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>10.12</td>\n",
              "      <td>9.960</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>27.220000</td>\n",
              "      <td>18.05</td>\n",
              "      <td>26.47</td>\n",
              "      <td>18.750</td>\n",
              "      <td>17.840</td>\n",
              "      <td>14.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.900</td>\n",
              "      <td>3.420</td>\n",
              "      <td>3.81</td>\n",
              "      <td>4.580</td>\n",
              "      <td>3.56</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.86</td>\n",
              "      <td>3.530</td>\n",
              "      <td>3.41</td>\n",
              "      <td>0.850</td>\n",
              "      <td>...</td>\n",
              "      <td>8.31</td>\n",
              "      <td>9.975</td>\n",
              "      <td>14.35</td>\n",
              "      <td>13.095000</td>\n",
              "      <td>26.793616</td>\n",
              "      <td>18.31</td>\n",
              "      <td>20.53</td>\n",
              "      <td>15.785</td>\n",
              "      <td>18.605</td>\n",
              "      <td>15.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.900</td>\n",
              "      <td>3.420</td>\n",
              "      <td>3.81</td>\n",
              "      <td>4.580</td>\n",
              "      <td>3.56</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.86</td>\n",
              "      <td>3.530</td>\n",
              "      <td>3.41</td>\n",
              "      <td>0.850</td>\n",
              "      <td>...</td>\n",
              "      <td>6.50</td>\n",
              "      <td>9.990</td>\n",
              "      <td>11.78</td>\n",
              "      <td>18.590000</td>\n",
              "      <td>26.800000</td>\n",
              "      <td>18.57</td>\n",
              "      <td>14.59</td>\n",
              "      <td>12.820</td>\n",
              "      <td>19.370</td>\n",
              "      <td>15.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.900</td>\n",
              "      <td>3.420</td>\n",
              "      <td>3.81</td>\n",
              "      <td>4.580</td>\n",
              "      <td>3.56</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.86</td>\n",
              "      <td>3.530</td>\n",
              "      <td>3.41</td>\n",
              "      <td>0.850</td>\n",
              "      <td>...</td>\n",
              "      <td>17.77</td>\n",
              "      <td>10.370</td>\n",
              "      <td>15.32</td>\n",
              "      <td>13.510000</td>\n",
              "      <td>12.230000</td>\n",
              "      <td>14.68</td>\n",
              "      <td>16.35</td>\n",
              "      <td>18.140</td>\n",
              "      <td>18.410</td>\n",
              "      <td>17.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.505</td>\n",
              "      <td>1.975</td>\n",
              "      <td>2.13</td>\n",
              "      <td>2.545</td>\n",
              "      <td>2.44</td>\n",
              "      <td>2.48</td>\n",
              "      <td>1.99</td>\n",
              "      <td>2.025</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.795</td>\n",
              "      <td>...</td>\n",
              "      <td>2.82</td>\n",
              "      <td>5.520</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.130000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>3.23</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2.780</td>\n",
              "      <td>3.550</td>\n",
              "      <td>2.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32183</th>\n",
              "      <td>18.900</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>24.080</td>\n",
              "      <td>17.99</td>\n",
              "      <td>18.70</td>\n",
              "      <td>18.88</td>\n",
              "      <td>16.680</td>\n",
              "      <td>21.17</td>\n",
              "      <td>14.580</td>\n",
              "      <td>...</td>\n",
              "      <td>7.13</td>\n",
              "      <td>8.740</td>\n",
              "      <td>6.26</td>\n",
              "      <td>7.940000</td>\n",
              "      <td>8.240000</td>\n",
              "      <td>9.36</td>\n",
              "      <td>9.00</td>\n",
              "      <td>8.000</td>\n",
              "      <td>7.530</td>\n",
              "      <td>6.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32184</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>223.88</td>\n",
              "      <td>184.340</td>\n",
              "      <td>172.69</td>\n",
              "      <td>205.440000</td>\n",
              "      <td>207.640000</td>\n",
              "      <td>233.38</td>\n",
              "      <td>194.74</td>\n",
              "      <td>183.910</td>\n",
              "      <td>182.190</td>\n",
              "      <td>256.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32185</th>\n",
              "      <td>1.840</td>\n",
              "      <td>1.820</td>\n",
              "      <td>2.26</td>\n",
              "      <td>1.800</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1.69</td>\n",
              "      <td>1.95</td>\n",
              "      <td>1.200</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.360</td>\n",
              "      <td>...</td>\n",
              "      <td>0.83</td>\n",
              "      <td>4.830</td>\n",
              "      <td>6.50</td>\n",
              "      <td>37.437344</td>\n",
              "      <td>7.330000</td>\n",
              "      <td>5.83</td>\n",
              "      <td>7.00</td>\n",
              "      <td>5.480</td>\n",
              "      <td>5.160</td>\n",
              "      <td>8.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32186</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.97</td>\n",
              "      <td>5.700</td>\n",
              "      <td>6.41</td>\n",
              "      <td>6.880000</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>8.25</td>\n",
              "      <td>8.91</td>\n",
              "      <td>8.300</td>\n",
              "      <td>7.410</td>\n",
              "      <td>7.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32187</th>\n",
              "      <td>0.080</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.140</td>\n",
              "      <td>...</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32188 rows × 1034 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7eba0f27-fca5-484a-83dc-b0185328fdb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7eba0f27-fca5-484a-83dc-b0185328fdb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7eba0f27-fca5-484a-83dc-b0185328fdb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbJiJnu6W7Gk"
      },
      "outputs": [],
      "source": [
        "#noramalisation process\n",
        "scale = MinMaxScaler()\n",
        "scaled = scale.fit_transform(data.values.T).T\n",
        "mData = pd.DataFrame(data=scaled, columns=data.columns)\n",
        "preprData = pd.concat([infoData, mData], axis=1, sort=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxjfwy23XRuA",
        "outputId": "f306c7df-7399-4147-ab2b-0c9e46287189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       FLAG                           CONS_NO  2014-01-01 00:00:00  \\\n",
            "0         1  0387DD8A07E07FDA6271170F86AD9151             0.000000   \n",
            "1         1  4B75AC4F2D8434CFF62DB64D0BB43103             0.108235   \n",
            "2         1  B32AC8CC6D5D805AC053557AB05F5343             0.077443   \n",
            "3         1  EDFC78B07BA2908B3395C4EB2304665E             0.111323   \n",
            "4         1  6BCFD78138BC72A9BA1BFB0B79382192             0.141255   \n",
            "...     ...                               ...                  ...   \n",
            "32183     0  70E6E487AC4DC54FD912E4F01F08F4DB             0.178546   \n",
            "32184     0  9E726157C304B05D0057FCA8EF4A0DE4             0.000000   \n",
            "32185     0  6B748296C244E9AC3F80A61D859BE74E             0.049149   \n",
            "32186     0  038BAAC5F0A7AFA46BAAC8CB76E77C67             0.000000   \n",
            "32187     0  C4D81686BEF24091C802E6C38C4166C4             0.027742   \n",
            "\n",
            "       2014-01-10 00:00:00  2014-01-11 00:00:00  2014-01-12 00:00:00  \\\n",
            "0                 0.000000             0.000000             0.000000   \n",
            "1                 0.127642             0.142198             0.170936   \n",
            "2                 0.091330             0.101744             0.122307   \n",
            "3                 0.131284             0.146255             0.175813   \n",
            "4                 0.185367             0.199915             0.238866   \n",
            "...                    ...                  ...                  ...   \n",
            "32183             0.000000             0.000000             0.227481   \n",
            "32184             0.000000             0.000000             0.000000   \n",
            "32185             0.048615             0.060368             0.048080   \n",
            "32186             0.000000             0.000000             0.000000   \n",
            "32187             0.086694             0.027742             0.034677   \n",
            "\n",
            "       2014-01-13 00:00:00  2014-01-14 00:00:00  2014-01-15 00:00:00  \\\n",
            "0                 0.000000             0.000000             0.000000   \n",
            "1                 0.132867             0.158620             0.144064   \n",
            "2                 0.095068             0.113494             0.103080   \n",
            "3                 0.136658             0.163145             0.148174   \n",
            "4                 0.229011             0.232765             0.186775   \n",
            "...                    ...                  ...                  ...   \n",
            "32183             0.169950             0.176657             0.178357   \n",
            "32184             0.000000             0.000000             0.000000   \n",
            "32185             0.033122             0.045142             0.052087   \n",
            "32186             0.000000             0.000000             0.000000   \n",
            "32187             0.000000             0.000000             0.000000   \n",
            "\n",
            "       2014-01-16 00:00:00  ...  2016-09-28 00:00:00  2016-09-29 00:00:00  \\\n",
            "0                 0.000000  ...             0.276942             0.272564   \n",
            "1                 0.131748  ...             0.310149             0.372290   \n",
            "2                 0.094267  ...             0.173580             0.266779   \n",
            "3                 0.135506  ...             0.682138             0.398074   \n",
            "4                 0.190060  ...             0.264676             0.518090   \n",
            "...                    ...  ...                  ...                  ...   \n",
            "32183             0.157574  ...             0.067356             0.082566   \n",
            "32184             0.000000  ...             0.702059             0.578066   \n",
            "32185             0.032054  ...             0.022170             0.129016   \n",
            "32186             0.000000  ...             0.304567             0.290792   \n",
            "32187             0.000000  ...             0.083226             0.156049   \n",
            "\n",
            "       2016-09-03 00:00:00  2016-09-30 00:00:00  2016-09-04 00:00:00  \\\n",
            "0                 0.463030             0.207980             0.744898   \n",
            "1                 0.535575             0.488736             1.000000   \n",
            "2                 0.314580             0.496438             0.715683   \n",
            "3                 0.588090             0.518609             0.469474   \n",
            "4                 0.292833             0.293772             0.394199   \n",
            "...                    ...                  ...                  ...   \n",
            "32183             0.059138             0.075008             0.077842   \n",
            "32184             0.541534             0.644233             0.651132   \n",
            "32185             0.173623             1.000000             0.195794   \n",
            "32186             0.327014             0.350991             0.494857   \n",
            "32187             0.055484             0.055484             0.058952   \n",
            "\n",
            "       2016-09-05 00:00:00  2016-09-06 00:00:00  2016-09-07 00:00:00  \\\n",
            "0                 0.493953             0.724374             0.513110   \n",
            "1                 0.683372             0.766227             0.589133   \n",
            "2                 0.495904             0.389620             0.342353   \n",
            "3                 0.563522             0.627629             0.696342   \n",
            "4                 0.303158             0.361349             0.260922   \n",
            "...                    ...                  ...                  ...   \n",
            "32183             0.088423             0.085022             0.075575   \n",
            "32184             0.731850             0.610680             0.576718   \n",
            "32185             0.155727             0.186979             0.146378   \n",
            "32186             0.420884             0.454554             0.423434   \n",
            "32187             0.065887             0.100565             0.079758   \n",
            "\n",
            "       2016-09-08 00:00:00  2016-09-09 00:00:00  \n",
            "0                 0.488207             0.408298  \n",
            "1                 0.694382             0.575510  \n",
            "2                 0.517268             0.425137  \n",
            "3                 0.706706             0.664480  \n",
            "4                 0.333192             0.238396  \n",
            "...                    ...                  ...  \n",
            "32183             0.071135             0.063389  \n",
            "32184             0.571324             0.802908  \n",
            "32185             0.137830             0.217964  \n",
            "32186             0.378030             0.397926  \n",
            "32187             0.069355             0.090161  \n",
            "\n",
            "[32188 rows x 1036 columns]\n"
          ]
        }
      ],
      "source": [
        "print(preprData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0NY2YTuXQwW"
      },
      "outputs": [],
      "source": [
        "preprData.to_csv(r'data_preprocessing.csv', index=False, header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvqy8aRYhpWy"
      },
      "source": [
        "##The Preprocessed file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAF4LSDQXdRe"
      },
      "outputs": [],
      "source": [
        "#importing  libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, \\\n",
        "    precision_recall_fscore_support, roc_auc_score\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.layers import Dense, Conv1D, Flatten, Conv2D,AveragePooling2D,MaxPooling2D,Dropout\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsGzL9nXYQPH"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)\n",
        "epochs_number = 3  # number of epochs for the neural networks\n",
        "test_set_size = 0.2 # percentage of the test size comparing to the whole dataset\n",
        "oversampling_flag = 0  # set to 1 to over-sample the minority class\n",
        "oversampling_percentage = 0.2  # percentage of the minority class after the oversampling comparing to majority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB9ckAwL7aqm",
        "outputId": "19dfe16a-3c28-4429-fd4a-71923b4de8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Consumers:                     28609\n",
            "Consumers with Fraud:                 3579\n",
            "Total Consumers:                      32188\n",
            "Classification assuming no fraud:     88.88 %\n",
            "Test set assuming no fraud:           89.27 %\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rawData = pd.read_csv('data_preprocessing.csv')\n",
        "# Setting the target and dropping the unnecessary columns\n",
        "y = rawData[['FLAG']]\n",
        "X = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
        "\n",
        "print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
        "print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
        "print('Total Consumers:                     ', y.shape[0])\n",
        "print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n",
        "# columns reindexing according to dates\n",
        "X.columns = pd.to_datetime(X.columns)\n",
        "X = X.reindex(X.columns, axis=1)\n",
        "\n",
        "# Splitting the dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y['FLAG'], test_size=test_set_size, random_state=42)\n",
        "print(\"Test set assuming no fraud:           %.2f\" % (y_test[y_test == 0].count() / y_test.shape[0] * 100), \"%\\n\")\n",
        "\n",
        "# Oversampling of minority class to encounter the imbalanced learning\n",
        "if oversampling_flag == 1:\n",
        "  over = SMOTE(sampling_strategy=oversampling_percentage, random_state=0)\n",
        "  X_train, y_train = over.fit_resample(X_train, y_train)\n",
        "  print(\"Oversampling statistics in training set: \")\n",
        "  print('Normal Consumers:                    ', y_train[y_train == 0].count())\n",
        "  print('Consumers with Fraud:                ', y_train[y_train == 1].count())\n",
        "  print(\"Total Consumers                      \", X_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-unOLqLwlwO"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvYvSWeDYmhr"
      },
      "outputs": [],
      "source": [
        "def results(y_test, y_pred):\n",
        "    print(\"Accuracy\", 100 * accuracy_score(y_test, y_pred))\n",
        "    print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
        "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "    print(\"F1:\", 100 * precision_recall_fscore_support(y_test, y_pred)[2])\n",
        "    print(\"AUC:\", 100 * roc_auc_score(y_test, y_pred))\n",
        "    print(\"confusion matrix:\",confusion_matrix(y_test, y_pred), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-gz2evpSHNw",
        "outputId": "f59407a2-30d7-426e-e189-af704a6ed22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D - Convolutional Neural Network:\n",
            "Epoch 1/3\n",
            "725/725 [==============================] - 6s 8ms/step - loss: 0.6048 - accuracy: 0.8868 - val_loss: 0.2997 - val_accuracy: 0.8901\n",
            "Epoch 2/3\n",
            "725/725 [==============================] - 5s 7ms/step - loss: 0.5654 - accuracy: 0.8951 - val_loss: 0.2932 - val_accuracy: 0.8897\n",
            "Epoch 3/3\n",
            "725/725 [==============================] - 5s 7ms/step - loss: 0.5272 - accuracy: 0.9080 - val_loss: 0.2966 - val_accuracy: 0.8889\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " module_wrapper_28 (ModuleWr  (None, 142, 5, 32)       704       \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_29 (ModuleWr  (None, 22720)            0         \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_30 (ModuleWr  (None, 100)              2272100   \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_31 (ModuleWr  (None, 100)              10100     \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_32 (ModuleWr  (None, 64)               6464      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_33 (ModuleWr  (None, 32)               2080      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_34 (ModuleWr  (None, 1)                33        \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_35 (ModuleWr  (None, 1)                0         \n",
            " apper)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,291,481\n",
            "Trainable params: 2,291,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1D - Convolutional Neural Network:\n",
            "Epoch 1/3\n",
            "805/805 [==============================] - 11s 12ms/step - loss: 0.3015 - accuracy: 0.8930\n",
            "Epoch 2/3\n",
            "805/805 [==============================] - 10s 12ms/step - loss: 0.2213 - accuracy: 0.9174\n",
            "Epoch 3/3\n",
            "805/805 [==============================] - 10s 12ms/step - loss: 0.1510 - accuracy: 0.9444\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " module_wrapper_36 (ModuleWr  (None, 1028, 100)        800       \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_37 (ModuleWr  (None, 102800)           0         \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_38 (ModuleWr  (None, 100)              10280100  \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_39 (ModuleWr  (None, 100)              10100     \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_40 (ModuleWr  (None, 64)               6464      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_41 (ModuleWr  (None, 1)                65        \n",
            " apper)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,297,529\n",
            "Trainable params: 10,297,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy 89.2668530599565\n",
            "RMSE: 0.3276148186520795\n",
            "MAE: 0.10733146940043492\n",
            "F1: [94.32909315  0.        ]\n",
            "AUC: 50.0\n",
            "confusion matrix: [[5747    0]\n",
            " [ 691    0]] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('2D - Convolutional Neural Network:')\n",
        "\n",
        "n_array_X_train = X_train.to_numpy()\n",
        "n_array_X_train_extended = np.hstack((n_array_X_train,np.zeros((n_array_X_train.shape[0],2))))\n",
        "#an exact multiple of 7\n",
        "week =[]\n",
        "for i in range(n_array_X_train_extended.shape[0]):\n",
        "  a = np.reshape(n_array_X_train_extended[i],(-1,7,1))\n",
        "  week.append(a)\n",
        "X_train_reshaped =np.array(week)\n",
        "\n",
        "# Transforming the dataset into tensors\n",
        "n_array_X_test = X_test.to_numpy()\n",
        "n_array_X_test_extended = np.hstack((n_array_X_test,np.zeros((n_array_X_test.shape[0],2))))\n",
        "week2 =[]\n",
        "for i in range(n_array_X_test_extended.shape[0]):\n",
        "  b = np.reshape(n_array_X_test_extended[i],(-1,7,1))\n",
        "  week2.append(b)\n",
        "X_test_reshaped =np.array(week2)\n",
        "input_shape=(1,148,7,1)\n",
        "# model1 creation\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D( kernel_size=(7,3),filters=32, input_shape=input_shape[1:], activation='relu',\n",
        "                  data_format ='channels_last'))\n",
        "#model1.add(MaxPooling2D(kernel_size=(7,3)))\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(100, activation='relu'))\n",
        "model1.add(Dense(100, activation='relu'))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "model1.add(Dense(32, activation='relu'))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "model1.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "model1.fit(X_train_reshaped, y_train, epochs=3, validation_split=0.1, shuffle=False, verbose=1)\n",
        "prediction2 = model1.predict(X_test_reshaped)\n",
        "model1.summary()\n",
        "#y_pred = np.where(prediction2> 0.5, 1, 0)\n",
        "#results(y_test, y_pred)\n",
        "print('1D - Convolutional Neural Network:')\n",
        "\n",
        "# Transforming the dataset into tensors\n",
        "X_train = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Model creation\n",
        "model = Sequential()\n",
        "model.add(Conv1D(100, kernel_size=7, input_shape=(1034, 1), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # model.fit(X_train, y_train, epochs=1, validation_split=0.1, shuffle=False, verbose=1)\n",
        "model.fit(X_train, y_train, epochs=epochs_number, validation_split=0, shuffle=False, verbose=1)\n",
        "prediction = model.predict(X_test)\n",
        "model.summary()\n",
        "\n",
        "n= len(prediction2)\n",
        "for i in range(n):\n",
        "  if (prediction[i]!=prediction2[i]):\n",
        "    prediction[i]=0\n",
        "results(y_test,prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n= len(prediction)\n",
        "for i in range(n):\n",
        "  if (prediction2[i]!=prediction[i]):\n",
        "    prediction2[i]==0\n",
        "    results(y_test,prediction)"
      ],
      "metadata": {
        "id": "9c4EOl1Fp_Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUxpXpq6CYim"
      },
      "outputs": [],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLYaT3JgCCxa"
      },
      "outputs": [],
      "source": [
        "results(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFA8TuqhZdB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e1f9e3-452d-4ca4-a1dd-d80034f58461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D - Convolutional Neural Network:\n",
            "Epoch 1/3\n",
            "805/805 [==============================] - 11s 13ms/step - loss: 0.3010 - accuracy: 0.8922\n",
            "Epoch 2/3\n",
            "805/805 [==============================] - 10s 12ms/step - loss: 0.2210 - accuracy: 0.9171\n",
            "Epoch 3/3\n",
            "805/805 [==============================] - 10s 12ms/step - loss: 0.1466 - accuracy: 0.9470\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " module_wrapper_42 (ModuleWr  (None, 1028, 100)        800       \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_43 (ModuleWr  (None, 102800)           0         \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_44 (ModuleWr  (None, 100)              10280100  \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_45 (ModuleWr  (None, 100)              10100     \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_46 (ModuleWr  (None, 64)               6464      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_47 (ModuleWr  (None, 1)                65        \n",
            " apper)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,297,529\n",
            "Trainable params: 10,297,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy 90.4318111214663\n",
            "RMSE: 0.3093248919588223\n",
            "MAE: 0.09568188878533707\n",
            "F1: [94.67588591 52.8330781 ]\n",
            "AUC: 72.6147688707907\n",
            "confusion matrix: [[5477  270]\n",
            " [ 346  345]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('1D - Convolutional Neural Network:')\n",
        "\n",
        "# Transforming the dataset into tensors\n",
        "X_train = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Model creation\n",
        "model = Sequential()\n",
        "model.add(Conv1D(100, kernel_size=7, input_shape=(1034, 1), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # model.fit(X_train, y_train, epochs=1, validation_split=0.1, shuffle=False, verbose=1)\n",
        "model.fit(X_train, y_train, epochs=epochs_number, validation_split=0, shuffle=False, verbose=1)\n",
        "prediction = model.predict(X_test)\n",
        "model.summary()\n",
        "y_pred = np.where(prediction> 0.5, 1, 0)\n",
        "results(y_test, y_pred)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU9kRWQo_J7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b8ae4074-f469-4ee0-f7ea-4f0c90c1a033"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f229a98515a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprediction2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
          ]
        }
      ],
      "source": [
        "n= len(prediction)\n",
        "for i in range(n):\n",
        "  if (prediction2[i]!=prediction[i]):\n",
        "    prediction2[i]=0\n",
        "results(y_test,prediction2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zqQNm0o5Qhp"
      },
      "outputs": [],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnoTlJERjivn"
      },
      "outputs": [],
      "source": [
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mZbXlVok2w9"
      },
      "outputs": [],
      "source": [
        "y_pred = np.where(prediction> 0.5, 1, 0)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oPMaixd8jCJ"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fexsZ2wFk-pX"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdwrCXYno_Cu"
      },
      "outputs": [],
      "source": [
        "results(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84eTMhQa81Te"
      },
      "source": [
        "ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dae6gmRA7CG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd15016-ea97-42af-85f4-0aaf64c28e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "805/805 [==============================] - 36s 43ms/step - loss: 0.3574 - accuracy: 0.8869\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " module_wrapper_48 (ModuleWr  (None, 1034, 1000)       2000      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_49 (ModuleWr  (None, 1034, 100)        100100    \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_50 (ModuleWr  (None, 1034, 100)        10100     \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_51 (ModuleWr  (None, 1034, 100)        10100     \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_52 (ModuleWr  (None, 1034, 10)         1010      \n",
            " apper)                                                          \n",
            "                                                                 \n",
            " module_wrapper_53 (ModuleWr  (None, 1034, 1)          11        \n",
            " apper)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,321\n",
            "Trainable params: 123,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1000, input_dim=1034, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # model.fit(X_train, y_train, validation_split=0, epochs=i, shuffle=True, verbose=0)\n",
        "model.fit(X_train, y_train, validation_split=0, epochs=1, shuffle=True, verbose=1)\n",
        "pred = model.predict(X_test)\n",
        "y_pred = np.where(pred> 0.05, 1, 0)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1igZBGrD3sbZ"
      },
      "outputs": [],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuwK48kN4nBw"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyq95blgHZf2"
      },
      "outputs": [],
      "source": [
        "y_prediction = np.where(pred> 0.05, 0, 1)\n",
        "y_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWIx8fkTHide"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37r0MrzXHWI-"
      },
      "outputs": [],
      "source": [
        "accuracy_score( y_prediction,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W88ieQzngZuL"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "results(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17ye8kjzf_No"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5nf7eJSfwbS"
      },
      "outputs": [],
      "source": [
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szKtFIaka_WL"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"RMSE:\", mean_squared_error(y_test, prediction, squared=False))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, prediction)) \n",
        "print(\"F1:\", 100 * precision_recall_fscore_support(y_test, prediction)[2])\n",
        "print(\"AUC:\", 100 * roc_auc_score(y_test, prediction))\n",
        "print(\"confusion matrix:\",confusion_matrix(y_test, prediction), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Yhwu0rf13Ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aef033c-c87e-49d9-e0ed-ee050294bcec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-7857f433bc6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features='auto',  # max_depth=10,\n\u001b[1;32m      2\u001b[0m                                    random_state=0, n_jobs=-1)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         )\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ],
      "source": [
        "model = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features='auto',  # max_depth=10,\n",
        "                                   random_state=0, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "print(\"Random Forest\")\n",
        "results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo5n7WbD1-9Z"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(C=1000, max_iter=1000, n_jobs=-1, solver='newton-cg')\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf3oNjIu2D4V"
      },
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier(random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "results(y_test, prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWEOlKhMp_fo"
      },
      "outputs": [],
      "source": [
        "model = SVC(random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)\n",
        "results(y_test, prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2jmWPOl4ao1"
      },
      "source": [
        "THE VISUALIZATION PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KadOfC-TxTs2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "rawData1 = pd.read_csv('visualization.csv', nrows=3) #taking first 3 rows\n",
        "cols = rawData1.columns\n",
        "rawData2 = pd.read_csv('visualization.csv', skiprows=187) #removing first 189 rows\n",
        "rawData2.columns = cols\n",
        "data = pd.concat([rawData1, rawData2], ignore_index=True) #ignore_index=True to make row index number \n",
        "                                            #continuous((0,1)+(0,1) ->form(0,1,0,1) to->(0,1,2,3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNKGEZ7JSb1g"
      },
      "outputs": [],
      "source": [
        "rawData1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-7Sh1oVw2_-"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik1BziDj4Ndp"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJKKAKaF21x1"
      },
      "outputs": [],
      "source": [
        "#plot 1D graph for consumer\n",
        "fig, axs = plt.subplots(2, 1,figsize=(14,4))\n",
        "fig.suptitle('Consumers With Fraud', fontsize=12)\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "\n",
        "data.loc[2].plot(ax=axs[1], color='firebrick', grid=True)\n",
        "axs[1].set_title('Consumer 1', fontsize=16)\n",
        "axs[1].set_xlabel('Dates of Consumption')\n",
        "axs[1].set_ylabel('Consumption')\n",
        "\n",
        "data.loc[0].plot(ax=axs[0], color='firebrick', grid=True)\n",
        "axs[0].set_title('Consumer 0', fontsize=16)\n",
        "axs[0].set_xlabel('Dates of Consumption')\n",
        "axs[0].set_ylabel('Consumption')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPBICszP2yGc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig, axs = plt.subplots(2, 1,figsize=(14,4))\n",
        "fig.suptitle('Consumers Without Fraud', fontsize=12)\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "\n",
        "data.loc[3].plot(ax=axs[0], color='#646400', grid=True)\n",
        "axs[0].set_title('Consumer 33218', fontsize=12)\n",
        "axs[0].set_xlabel('Dates of Consumption')\n",
        "axs[0].set_ylabel('Consumption')\n",
        "\n",
        "data.loc[4].plot(ax=axs[1], color='#646400', grid=True)\n",
        "axs[1].set_title('Consumer 33218 ', fontsize=12)\n",
        "axs[1].set_xlabel('Dates of Consumption')\n",
        "axs[1].set_ylabel('Consumption')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZekPKjwo3NUV"
      },
      "outputs": [],
      "source": [
        "#statistics for consumer \n",
        "#with fraud\n",
        "fig2, axs2 = plt.subplots(2, 2,figsize=(14,4))\n",
        "fig2.suptitle('Statistics for Consumers with Fraud', fontsize=16)\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "\n",
        "data.loc[0].plot(ax=axs2[0, 0], color='firebrick', grid=True)\n",
        "axs2[0, 0].set_title('Consumption of Consumer 0', fontsize=16)\n",
        "axs2[0, 0].set_xlabel('Dates of Consumption')\n",
        "axs2[0, 0].set_ylabel('Consumption')\n",
        "\n",
        "data.loc[0].hist(color='firebrick', ax=axs2[0, 1], grid=True)\n",
        "axs2[0, 1].set_title('Histogram', fontsize=16)\n",
        "axs2[0, 1].set_xlabel('Values')\n",
        "axs2[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "data.loc[0].plot.kde(color='firebrick', ax=axs2[1, 0], grid=True)\n",
        "axs2[1, 0].set_title('Density Estimation', fontsize=16)\n",
        "axs2[1, 0].set_xlabel('Values')\n",
        "axs2[1, 0].set_ylabel('Density')\n",
        "\n",
        "data.loc[0].describe().drop(['count']).plot(kind='bar', ax=axs2[1, 1], color='firebrick', grid=True)\n",
        "axs2[1, 1].set_title('Statistics', fontsize=16)\n",
        "axs2[1, 1].set_ylabel('Values')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AtpWFhy3jSx"
      },
      "outputs": [],
      "source": [
        "\n",
        "#without fraud\n",
        "fig3, axs3 = plt.subplots(2, 2,figsize=(14,4))\n",
        "fig3.suptitle('Statistics for Consumers without Fraud', fontsize=16)\n",
        "plt.subplots_adjust(hspace=0.8)\n",
        "data.loc[4].plot(ax=axs3[0, 0], color='teal', grid=True)\n",
        "axs3[0, 0].set_title('Consumption of Consumer ', fontsize=16)\n",
        "axs3[0, 0].set_xlabel('Dates of Consumption')\n",
        "axs3[0, 0].set_ylabel('Consumption')\n",
        "\n",
        "data.loc[4].hist(color='teal', ax=axs3[0, 1])\n",
        "axs3[0, 1].set_title('Histogram', fontsize=16)\n",
        "axs3[0, 1].set_xlabel('Values')\n",
        "axs3[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "data.loc[4].plot.kde(color='teal', ax=axs3[1, 0], grid=True)\n",
        "axs3[1, 0].set_title('Density Estimation', fontsize=16)\n",
        "axs3[1, 0].set_xlabel('Values')\n",
        "axs3[1, 0].set_ylabel('Density')\n",
        "\n",
        "data.loc[4].describe().drop(['count']).plot(kind='bar', ax=axs3[1, 1], color='teal', grid=True)\n",
        "axs3[1, 1].set_title('Statistics', fontsize=16)\n",
        "axs3[1, 1].set_ylabel('Values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLXRVBWPdd80"
      },
      "outputs": [],
      "source": [
        "# 2D data plot \n",
        "fig4, axs4 = plt.subplots(2, 1)\n",
        "fig4.suptitle('Four Week Consumption', fontsize=16)\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for i in range(59, 83, 7):\n",
        "    axs4[0].plot(data.iloc[1,i:i + 7].to_numpy(), marker='>', linestyle='-',\n",
        "                 label='$week {i}$'.format(i=(i % 58) % 6))\n",
        "#xs4[0].legend(loc='best')\n",
        "axs4[0].set_title('With Fraud', fontsize=14)\n",
        "axs4[0].set_ylabel('Consumption')\n",
        "axs4[0].grid(True)\n",
        "\n",
        "for i in range(59, 83, 7):\n",
        "    axs4[1].plot(data.iloc[6,i:i + 7].to_numpy(), marker='>', linestyle='-',\n",
        "                 label='$week {i}$'.format(i=(i % 58) % 6))\n",
        "#xs4[1].legend(loc='best')\n",
        "axs4[1].set_title('Without fraud' , fontsize=14)\n",
        "axs4[1].set_ylabel('Consumption')\n",
        "axs4[1].grid(True)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PO36X6aeb8S"
      },
      "outputs": [],
      "source": [
        "fig5, axs5 = plt.subplots(1, 2,figsize=(14,4))\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "a = []\n",
        "for i in range(59, 81, 7):\n",
        "    a.append(data.iloc[2, i:i + 7].to_numpy())\n",
        "cor = pd.DataFrame(a).transpose().corr()\n",
        "cax = axs5[0].matshow(cor)\n",
        "for (i, j), z in np.ndenumerate(cor):\n",
        "    axs5[0].text(j, i, '{:0.1f}'.format(z), ha='center', va='center', color='white')\n",
        "alpha = ['week 1', 'week 2', 'week 3', 'week 4']\n",
        "axs5[0].set_xticklabels([''] + alpha)\n",
        "axs5[0].set_yticklabels([''] + alpha)\n",
        "axs5[0].set_title('Customer without Fraud', fontsize=16)\n",
        "\n",
        "\n",
        "a = []\n",
        "for i in range(59, 83, 7):\n",
        "    a.append(data.iloc[4, i:i + 7].to_numpy())\n",
        "cor = pd.DataFrame(a).transpose().corr()\n",
        "cax = axs5[1].matshow(cor)\n",
        "for (i, j), z in np.ndenumerate(cor):\n",
        "    axs5[1].text(j, i, '{:0.1f}'.format(z), ha='center', va='center', color='white')\n",
        "axs5[1].set_xticklabels([''] + alpha)\n",
        "axs5[1].set_yticklabels([''] + alpha)\n",
        "axs5[1].set_title('Customer with Fraud', fontsize=16)\n",
        "fig5.colorbar(cax)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "power theft.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}